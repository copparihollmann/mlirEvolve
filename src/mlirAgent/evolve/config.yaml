experiment:
  name: "magellan_llvm_inlining"
  max_iterations: 100

llm:
  model: "gpt-4o" # Tier 1 Reasoning
  temperature: 0.8

evolution:
  strategy: "map_elites" # Quality-Diversity search is crucial for exploration
  population_size: 50

prompt:
  system_message: |
    You are an LLVM Compiler Engineer. Your goal is to optimize the `getAdviceImpl` function in C++.
    
    CRITICAL INSTRUCTION: HIERARCHICAL SEARCH
    Do not hardcode magic numbers. Instead, expose them as `cl::opt` flags so the autotuner can find the best values.
    
    Use the format:
    // [hyperparam]: flag-name, type, min, max
    static cl::opt<int> MyFlag("flag-name", cl::init(10), cl::Hidden);
    
    Focus on logic: Loop depth, Call site hotness (BFI), and Vector instruction bonuses.