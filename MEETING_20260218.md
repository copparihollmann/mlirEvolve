# LLM-Guided Compiler Optimization: Evolving LLVM Heuristics

## Background: Magellan (ICML 2025)

- **Key idea**: LLMs propose code *structure* (which features, how to combine), Optuna tunes numeric knobs
- Two-level optimization: outer loop = LLM (combinatorial/structural), inner loop = Optuna (continuous/integer)
- Evolved LLVM inlining heuristic and register allocation priority on CTMark benchmarks
- Results: **4.27–8.79% binary size reduction** on CTMark for inlining
- Also found "surprisingly simple constant-value policy" for register allocation that matched hand-crafted heuristics

## What We Built

### Infrastructure
- **OpenEvolve + ManualLLM**: evolutionary framework with file-based prompt/response interface
- **manual_run.py**: orchestrator with `--wait` mode (external LLM responds) and `--auto` mode (canned strategies)
- **Evaluator pipeline**: patch C++ into LLVM → ninja rebuild (~3.5s) → opt → llc → gcc → measure binary size + runtime
- **CTMark benchmarks**: 8 programs (sqlite3, spass, tramp3d-v4, consumer-typeset, mafft, bullet, kimwitu, lencod) pre-compiled to .bc

### LLVM Integration
- Created `EvolvedInlineCost.{h,cpp}` in `llvm/lib/Analysis/`
- Hook in `InlineCost.cpp`: `-use-evolved-inline-cost` flag redirects to evolved function
- `InlineCostFeatures` array provides 25 features (call overhead, callee penalties, SROA savings, constant args, etc.)
- Convention: negative return = inline, positive = don't inline

### Optuna Inner-Loop (new, Phase 2)
- `[hyperparam]` annotation convention in C++ source:
  ```cpp
  // [hyperparam]: ae-inline-base-threshold, int, 50, 1000
  static cl::opt<int> BaseThreshold("ae-inline-base-threshold", cl::init(225), ...);
  ```
- Evaluator extracts annotations, runs Optuna trials on 3-benchmark subset (sqlite3, spass, tramp3d-v4)
- Final evaluation uses tuned flags on all 8 benchmarks
- `EVOLVE_OPTUNA_TRIALS` env var (default 20, 0 = disable)

### Register Allocation Priority Task (new, Phase 2)
- Created `EvolvedRegAllocPriority.{h,cpp}` in `llvm/lib/CodeGen/`
- Hook in `RegAllocGreedy.cpp`: `-use-evolved-regalloc-priority` flag
- Feature struct: Size, Stage, IsLocal, ForceGlobal, AllocationPriority, HasPreference, NumAllocatable, etc.
- Scoring: 5x runtime speedup + 1x binary size reduction (runtime-weighted)
- Ready to run — scheduled for next session

## Experiment A: No Optuna, 10 Iterations, Claude Responder

- **Date**: 2026-02-17
- **Config**: CTMark 8 benchmarks, ~5 min/iteration, Claude Code as responder
- **Best score: 8.65 (8.78% binary size reduction)** at iteration 3

| Iter | Score | Binary Red. | Strategy |
|------|-------|-------------|----------|
| 1 | 7.52 | 8.13% | threshold=150, multi-block/nested penalties |
| 2 | -3.26 | -1.82% | ultra-conservative Os-level (HURT tramp3d) |
| **3** | **8.65** | **8.78%** | **selective inlining, constant_args bonus** |
| 4 | 6.09 | 6.18% | feature-ratio approach |
| 5 | -0.24 | -0.82% | quadratic penalty |
| 6 | 8.51 | ~8.5% | LLVM threshold-aware |
| 7 | 8.01 | ~8.0% | dead-code-aware |
| 8 | 8.01 | ~8.0% | refined iteration 1 |
| 9 | 5.71 | ~5.7% | minimal heuristic |
| 10 | 8.50 | ~8.5% | ensemble best |

### Per-Benchmark Breakdown (Best, Iteration 3)

| Benchmark | Language | Binary Red. % | Notes |
|-----------|----------|---------------|-------|
| sqlite3 | C | 19.7% | Big wins from constant folding |
| spass | C | 18.2% | Theorem prover, many small functions |
| consumer-typeset | C | 13.2% | Document typesetter |
| mafft | C | 12.2% | Sequence alignment |
| lencod | C | 7.9% | H.264 encoder |
| bullet | C++ | 7.3% | Physics simulation |
| tramp3d-v4 | C++ | 6.7% | Template-heavy — needs inlining! |
| kimwitu | C++ | 0.4% | Tree pattern matcher |

### Best Heuristic Key Features
- **BaseThreshold = 100** (between -O2 @ 225 and -Os @ 75)
- **constant_args bonus** = -30 per const arg (key insight: inline where optimizer benefits)
- **unsimplified_common_instructions** 2.5x weight (guaranteed code bloat)
- **num_loops** 4x penalty (loop duplication = bad for size)
- **nested_inlines** +20 each + cost/2 (prevent cascading inlines)
- **multi-block** +30 penalty (complex control flow)
- **simplified_instructions** 150% bonus (trust LLVM's callsite analysis)

### Key Insight
Os-level inlining (very aggressive size reduction) **hurts** tramp3d-v4 because C++ templates generate small functions that MUST be inlined for specialization. The best heuristic uses **selective inlining** — inline only where constant propagation and dead code elimination will offset the code increase.

## Optuna Validation Test

Quick test: tuned the best program's 3 hyperparams with 3 Optuna trials

| | Untuned (Claude's picks) | Optuna-tuned |
|--|--------------------------|--------------|
| BaseThreshold | 100 | 80 |
| SROAWeight | 0 | 172 |
| SimplifyWeight | 150 | 111 |
| Subset score (3 bench) | 10.07 | **12.78** |
| Full score (8 bench) | 8.78 | 8.57 |

Optuna found better params on the 3-benchmark subset (+27%), but full-suite score was similar — tramp3d-v4 penalized the more aggressive threshold.

## Experiment C: With Optuna, 10 Iterations, Auto-Responder (COMPLETE)

- **Date**: 2026-02-18
- **Config**: 5 Optuna trials per iteration, 1800s eval timeout, auto-responder (10 diverse strategies)
- **Duration**: ~90 min total (~9 min/iteration with Optuna)
- **Best score: 8.66 (8.41% binary size reduction)** at iteration 2

| Iter | Score | Binary Red. | Optuna Threshold | SROA | Simplify | Strategy |
|------|-------|-------------|-----------------|------|----------|----------|
| 0 | 1.66 | 1.03% | 124 | 176 | 198 | selective + constant_args |
| 1 | 7.89 | 8.59% | 89 | 8 | 82 | proven best from Exp A |
| **2** | **8.66** | **8.41%** | **173** | **157** | **23** | **aggressive size reduction** |
| 3 | 7.65 | 8.11% | 210 | 160 | 170 | balanced SROA |
| 4 | 7.16 | 8.17% | 100 | 45 | 5 | conditional (small vs large) |
| 5 | 8.23 | 8.64% | 73 | 172 | 149 | ratio-based const_args |
| 6 | 2.11 | 1.62% | 393 | 31 | 48 | static-elimination (too aggressive) |
| 7 | 7.65 | 8.52% | 74 | 99 | 158 | simplified-dominant |
| 8 | 6.81 | 6.40% | 337 | 103 | 167 | minimal features |
| 9 | 1.18 | 1.81% | 146 | 85 | 171 | load-elimination |
| 10 | 7.00 | 7.73% | 135 | 124 | 7 | kitchen sink |

### Exp A vs Exp C Comparison

| Metric | Exp A (no Optuna) | Exp C (5 Optuna trials) |
|--------|-------------------|------------------------|
| Best score | 8.65 | **8.66** |
| Best binary reduction | **8.78%** | 8.41% |
| Best text reduction | **18.41%** | 16.20% |
| Positive iterations | 8/10 (80%) | **11/11 (100%)** |
| Avg positive score | **7.62** | 6.00 |
| Time per iteration | ~5 min | ~9 min |

### Per-Benchmark: Best Programs Compared

| Benchmark | Exp A | Exp C | Winner |
|-----------|-------|-------|--------|
| sqlite3 | **19.73%** | 15.91% | A |
| spass | **18.22%** | 14.61% | A |
| consumer-typeset | **13.15%** | 12.00% | A |
| mafft | **12.19%** | 11.50% | A |
| bullet | 7.17% | **7.44%** | C |
| tramp3d-v4 | 6.72% | **10.30%** | C |
| kimwitu | 0.35% | 0.35% | tie |
| lencod | **7.95%** | 6.39% | A |

### Key Findings from Optuna Comparison

1. **Optuna eliminates catastrophic failures**: 100% positive scores (vs 80% without) — Optuna can rescue bad code structures by finding good hyperparameters
2. **Similar peak performance**: Best scores nearly identical (8.66 vs 8.65) — the LLM already finds good structures; Optuna's main value is robustness
3. **Optuna helps tramp3d-v4**: Found threshold=173 > Exp A's 100, allowing more C++ template inlining (10.3% vs 6.7% reduction)
4. **Auto-responder diversity matters**: Some canned strategies scored poorly (iter 0, 6, 9) — LLM interaction quality > Optuna tuning
5. **2x time overhead**: 9 min/iter vs 5 min/iter, but eliminates wasted iterations

## Codex Experiment (Failed)

- Codex ran 10 iterations but scored 0.0 on every one
- Root cause: repo copy at `/scratch/ashvin/mlirEvolve-codex-run/` missing CTMark `.bc` files
- Built LLVM fine each time but evaluator found no benchmarks
- Fix for future: symlink testsuite dir into Codex repo copy

## Comparison with Magellan

| | Magellan (ICML 2025) | Our System |
|--|---------------------|------------|
| LLM | PaLM/Gemini (internal) | Claude Code (Opus) |
| Framework | FunSearch-style | OpenEvolve + ManualLLM |
| Inner-loop | Optuna | Optuna (added Phase 2) |
| Inlining best | 4.27–8.79% | **8.78%** (matches upper end) |
| + Optuna | +improvement | **8.66** (similar, more robust) |
| Iterations | 100s | **10** (much fewer needed) |
| RegAlloc | Evolved priority | Hook ready, experiment pending |
| Open source | No | Yes (mlirEvolve repo) |

## Next Steps

1. Run register allocation priority evolution (hook already in LLVM, task ready)
2. Try Codex as autonomous responder (fix benchmark path issue first)
3. Scale to more iterations (20-50) to explore further
4. Compare more LLM backends (Claude vs GPT-4 vs Gemini vs open-source)
